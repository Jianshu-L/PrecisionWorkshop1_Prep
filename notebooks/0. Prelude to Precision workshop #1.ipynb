{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Precision workshop\n",
    "\n",
    "## Credits\n",
    "This series of notebooks has been adapted from the excellent [tutorial](https://github.com/fonnesbeck/PyMC3_DataScienceLA) by [Chris Fonnesbeck](https://twitter.com/fonnesbeck?lang=en) (published under CCL 1.0) and contains material inspired by many talks.  We have tried to tweak the content and add new content to maximize explanatory power and reduce friction when learning but beware - Bayesian modelling is not an easy topic. This material is made available under the same license as the original tutorial by Chris Fonnesbeck (CCL 1.0).\n",
    "\n",
    "Other sources include:\n",
    "- Examples from [Getting started in PyMC3](http://docs.pymc.io/notebooks/getting_started.html) (Apache License 2.0)\n",
    "- Various talks by David MacKay, Ian Murray and others on the problem of inference\n",
    "\n",
    "Note that the much of the original material is left unchanged and the credit belongs to Chris Fonnesbeck. The original purpose of the tutorial is to introduce PyMC3 and its functionality - we hijack this a little bit to concentrate on Bayesian modelling in general using PyMC3 as a vehicle.\n",
    "\n",
    "**We aim for this to be an enjoyable journey and learning exercise.**\n",
    "\n",
    "## Objectives\n",
    "At CEAi we are building this material to ensure everyone on the machine learning team at CEAi reaches a given level of proficiency before the start of the Precision Workshop on Bayesian modelling in the middle of May 2018.\n",
    "\n",
    "Specific objectives:\n",
    "- Basic proficiency in Bayesian modelling\n",
    "  - Commonly used probability distributions\n",
    "  - Construction of models from standard building blocks\n",
    "  - Understanding of PyMC3 as a vehicle to accomplish above tasks\n",
    "  - Clarity on various steps needed to write a model\n",
    "- Understanding inference via MCMC\n",
    "  - The Monte Carlo approach\n",
    "  - Simple algorithms for sampling complex distributions (Importance sampling, Rejection sampling, Slice sampling, ...)\n",
    "  - Markov Chain Monte Carlo as a method of estimating the posterior\n",
    "  - Understanding the Metropolis sampling algorithm in detail, testing how Metropolis fails, debugging it\n",
    "- Understand the idea of variational inference\n",
    "  - What is variational inference?\n",
    "  - Major differences between MCMC and variational approach\n",
    "  - The Evidence Lower Bound (ELBO)\n",
    "  - Mean field variational inference + example\n",
    "  \n",
    "The methodology of working on the topics is based on a few strategies: working through the tutorial material, extra reading, coding exercises, discussions and active reading group participation.\n",
    "  \n",
    "## Precision workshop #1 target content\n",
    "  \n",
    "From there, the Precision workshop will further build upon this basis with key topics like:\n",
    "- Failure modes of advanced MCMC, diagnostics, corrections\n",
    "- Key advances in variational inference (ADVI)\n",
    "- Building great models - heuristics, criticism, experiences\n",
    "- Model checking - answer to the question: is my model ready for the real world?\n",
    "- Critiquing models of immediate interest in current startups at CEAi, consulting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
